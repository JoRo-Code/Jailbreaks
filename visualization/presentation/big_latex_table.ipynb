{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results/all_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Model</th>\n",
       "      <th>Attack Succes Rate (Baseline)</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Attack Success Rate (LLM)</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Response Quality</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Utility</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Qwen2-0.5B-Instruct</td>\n",
       "      <td>6.7% ± 0.5%</td>\n",
       "      <td>33.0% ± 3.5%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.8% ± 3.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.6% ± 1.1%</td>\n",
       "      <td>8.8 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.59GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>5.0% ± 0.2%</td>\n",
       "      <td>21.0% ± 2.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0% ± 0.4%</td>\n",
       "      <td>21.6% ± 2.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1% ± 0.6%</td>\n",
       "      <td>3.2% ± 0.7%</td>\n",
       "      <td>9.9 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.96GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-3B-Instruct</td>\n",
       "      <td>6.2% ± 0.8%</td>\n",
       "      <td>19.2% ± 1.6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0% ± 1.3%</td>\n",
       "      <td>26.0% ± 2.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.6% ± 1.7%</td>\n",
       "      <td>42.4% ± 3.7%</td>\n",
       "      <td>12.5 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.07GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>3.8% ± 0.4%</td>\n",
       "      <td>24.8% ± 2.2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.4% ± 1.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.8% ± 2.8%</td>\n",
       "      <td>9.9 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.23GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>24.0% ± 0.6%</td>\n",
       "      <td>88.4% ± 2.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3% ± 0.2%</td>\n",
       "      <td>3.8% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5% ± 0.2%</td>\n",
       "      <td>3.8% ± 1.3%</td>\n",
       "      <td>9.8 ± 0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.32GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>99.3% ± 0.0%</td>\n",
       "      <td>100.0% ± 0.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0% ± 0.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6% ± 0.4%</td>\n",
       "      <td>10.4 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.73GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prefix Injection</td>\n",
       "      <td>Qwen2-0.5B-Instruct</td>\n",
       "      <td>94.9% ± 0.7%</td>\n",
       "      <td>97.6% ± 1.2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.6% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8% ± 1.0%</td>\n",
       "      <td>8.9 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.62GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>47.9% ± 2.2%</td>\n",
       "      <td>68.4% ± 2.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.6% ± 1.8%</td>\n",
       "      <td>73.0% ± 2.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1% ± 0.8%</td>\n",
       "      <td>3.4% ± 1.3%</td>\n",
       "      <td>10.1 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.95GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-3B-Instruct</td>\n",
       "      <td>85.7% ± 1.1%</td>\n",
       "      <td>98.6% ± 0.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.8% ± 0.5%</td>\n",
       "      <td>100.0% ± 0.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0% ± 0.4%</td>\n",
       "      <td>3.0% ± 0.6%</td>\n",
       "      <td>12.6 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.06GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>89.4% ± 0.2%</td>\n",
       "      <td>94.2% ± 1.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.4% ± 1.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4% ± 2.3%</td>\n",
       "      <td>10.2 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.81GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>31.2% ± 0.9%</td>\n",
       "      <td>71.0% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8% ± 0.4%</td>\n",
       "      <td>2.0% ± 1.5%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.7% ± 0.3%</td>\n",
       "      <td>0.6% ± 0.4%</td>\n",
       "      <td>9.9 ± 0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.97GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>99.5% ± 0.0%</td>\n",
       "      <td>100.0% ± 0.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0% ± 0.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0% ± 0.0%</td>\n",
       "      <td>10.9 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.27GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ablation</td>\n",
       "      <td>Qwen2-0.5B-Instruct</td>\n",
       "      <td>97.4% ± 0.6%</td>\n",
       "      <td>99.0% ± 0.6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0% ± 0.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8% ± 0.7%</td>\n",
       "      <td>16.4 ± 0.0</td>\n",
       "      <td>2:59</td>\n",
       "      <td>4.62GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>97.5% ± 0.4%</td>\n",
       "      <td>99.8% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.3% ± 1.3%</td>\n",
       "      <td>98.6% ± 1.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1% ± 0.6%</td>\n",
       "      <td>3.6% ± 1.2%</td>\n",
       "      <td>19.5 ± 0.0</td>\n",
       "      <td>4:57</td>\n",
       "      <td>8.33GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-3B-Instruct</td>\n",
       "      <td>98.6% ± 0.7%</td>\n",
       "      <td>98.4% ± 1.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0% ± 0.1%</td>\n",
       "      <td>100.0% ± 0.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3% ± 0.8%</td>\n",
       "      <td>5.4% ± 1.4%</td>\n",
       "      <td>24.5 ± 0.0</td>\n",
       "      <td>2:14</td>\n",
       "      <td>14.65GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>92.5% ± 0.6%</td>\n",
       "      <td>99.2% ± 0.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.8% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8% ± 1.0%</td>\n",
       "      <td>18.7 ± 0.0</td>\n",
       "      <td>2:17</td>\n",
       "      <td>32.11GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>91.1% ± 0.9%</td>\n",
       "      <td>93.8% ± 1.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0% ± 0.7%</td>\n",
       "      <td>87.6% ± 1.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3% ± 0.6%</td>\n",
       "      <td>5.4% ± 0.9%</td>\n",
       "      <td>21.1 ± 0.0</td>\n",
       "      <td>4:05</td>\n",
       "      <td>33.48GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>95.7% ± 0.6%</td>\n",
       "      <td>98.8% ± 0.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0% ± 1.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2% ± 0.9%</td>\n",
       "      <td>21.4 ± 0.0</td>\n",
       "      <td>4:07</td>\n",
       "      <td>30.39GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ablation + Prefix Injection</td>\n",
       "      <td>Qwen2-0.5B-Instruct</td>\n",
       "      <td>99.1% ± 0.3%</td>\n",
       "      <td>99.6% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.2% ± 0.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4% ± 0.7%</td>\n",
       "      <td>16.6 ± 0.0</td>\n",
       "      <td>2:59</td>\n",
       "      <td>5.96GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>98.7% ± 0.4%</td>\n",
       "      <td>99.8% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.1% ± 0.6%</td>\n",
       "      <td>98.2% ± 0.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3% ± 0.3%</td>\n",
       "      <td>1.0% ± 0.6%</td>\n",
       "      <td>19.2 ± 0.0</td>\n",
       "      <td>4:57</td>\n",
       "      <td>10.60GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-3B-Instruct</td>\n",
       "      <td>99.7% ± 0.3%</td>\n",
       "      <td>99.6% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.9% ± 0.1%</td>\n",
       "      <td>99.6% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0% ± 0.1%</td>\n",
       "      <td>0.2% ± 0.4%</td>\n",
       "      <td>24.8 ± 0.0</td>\n",
       "      <td>2:14</td>\n",
       "      <td>16.95GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>97.6% ± 0.6%</td>\n",
       "      <td>98.0% ± 0.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0% ± 0.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8% ± 0.4%</td>\n",
       "      <td>19.1 ± 0.0</td>\n",
       "      <td>2:17</td>\n",
       "      <td>32.05GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>94.7% ± 0.7%</td>\n",
       "      <td>97.8% ± 0.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0% ± 0.6%</td>\n",
       "      <td>97.8% ± 0.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5% ± 0.3%</td>\n",
       "      <td>0.2% ± 0.4%</td>\n",
       "      <td>21.6 ± 0.0</td>\n",
       "      <td>4:05</td>\n",
       "      <td>33.49GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>98.5% ± 0.3%</td>\n",
       "      <td>98.6% ± 0.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.8% ± 1.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4% ± 1.2%</td>\n",
       "      <td>21.9 ± 0.0</td>\n",
       "      <td>4:07</td>\n",
       "      <td>30.39GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Output Aware</td>\n",
       "      <td>Qwen2-0.5B-Instruct</td>\n",
       "      <td>20.9% ± 1.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.1 ± 0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.59GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>12.3% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4% ± 1.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0% ± 0.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.9 ± 0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.96GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-3B-Instruct</td>\n",
       "      <td>16.9% ± 1.5%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0% ± 1.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.6% ± 1.2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.8 ± 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.07GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>6.6% ± 0.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.6 ± 0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.23GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>14.0% ± 0.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1% ± 0.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8% ± 0.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.9 ± 2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.32GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>99.9% ± 0.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.1 ± 0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.73GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Method                     Model  \\\n",
       "1                      Baseline       Qwen2-0.5B-Instruct   \n",
       "2                           NaN     Qwen2.5-1.5B-Instruct   \n",
       "3                           NaN       Qwen2.5-3B-Instruct   \n",
       "4                           NaN       Qwen2.5-7B-Instruct   \n",
       "5                           NaN     Llama-3.1-8B-Instruct   \n",
       "6                           NaN  Mistral-7B-Instruct-v0.1   \n",
       "7              Prefix Injection       Qwen2-0.5B-Instruct   \n",
       "8                           NaN     Qwen2.5-1.5B-Instruct   \n",
       "9                           NaN       Qwen2.5-3B-Instruct   \n",
       "10                          NaN       Qwen2.5-7B-Instruct   \n",
       "11                          NaN     Llama-3.1-8B-Instruct   \n",
       "12                          NaN  Mistral-7B-Instruct-v0.1   \n",
       "13                     Ablation       Qwen2-0.5B-Instruct   \n",
       "14                          NaN     Qwen2.5-1.5B-Instruct   \n",
       "15                          NaN       Qwen2.5-3B-Instruct   \n",
       "16                          NaN       Qwen2.5-7B-Instruct   \n",
       "17                          NaN     Llama-3.1-8B-Instruct   \n",
       "18                          NaN  Mistral-7B-Instruct-v0.1   \n",
       "19  Ablation + Prefix Injection       Qwen2-0.5B-Instruct   \n",
       "20                          NaN     Qwen2.5-1.5B-Instruct   \n",
       "21                          NaN       Qwen2.5-3B-Instruct   \n",
       "22                          NaN       Qwen2.5-7B-Instruct   \n",
       "23                          NaN     Llama-3.1-8B-Instruct   \n",
       "24                          NaN  Mistral-7B-Instruct-v0.1   \n",
       "25                 Output Aware       Qwen2-0.5B-Instruct   \n",
       "26                          NaN     Qwen2.5-1.5B-Instruct   \n",
       "27                          NaN       Qwen2.5-3B-Instruct   \n",
       "28                          NaN       Qwen2.5-7B-Instruct   \n",
       "29                          NaN     Llama-3.1-8B-Instruct   \n",
       "30                          NaN  Mistral-7B-Instruct-v0.1   \n",
       "\n",
       "   Attack Succes Rate (Baseline)     Unnamed: 3 Unnamed: 4  \\\n",
       "1                    6.7% ± 0.5%   33.0% ± 3.5%        NaN   \n",
       "2                    5.0% ± 0.2%   21.0% ± 2.4%        NaN   \n",
       "3                    6.2% ± 0.8%   19.2% ± 1.6%        NaN   \n",
       "4                    3.8% ± 0.4%   24.8% ± 2.2%        NaN   \n",
       "5                   24.0% ± 0.6%   88.4% ± 2.3%        NaN   \n",
       "6                   99.3% ± 0.0%  100.0% ± 0.0%        NaN   \n",
       "7                   94.9% ± 0.7%   97.6% ± 1.2%        NaN   \n",
       "8                   47.9% ± 2.2%   68.4% ± 2.9%        NaN   \n",
       "9                   85.7% ± 1.1%   98.6% ± 0.9%        NaN   \n",
       "10                  89.4% ± 0.2%   94.2% ± 1.0%        NaN   \n",
       "11                  31.2% ± 0.9%   71.0% ± 0.4%        NaN   \n",
       "12                  99.5% ± 0.0%  100.0% ± 0.0%        NaN   \n",
       "13                  97.4% ± 0.6%   99.0% ± 0.6%        NaN   \n",
       "14                  97.5% ± 0.4%   99.8% ± 0.4%        NaN   \n",
       "15                  98.6% ± 0.7%   98.4% ± 1.1%        NaN   \n",
       "16                  92.5% ± 0.6%   99.2% ± 0.7%        NaN   \n",
       "17                  91.1% ± 0.9%   93.8% ± 1.3%        NaN   \n",
       "18                  95.7% ± 0.6%   98.8% ± 0.9%        NaN   \n",
       "19                  99.1% ± 0.3%   99.6% ± 0.4%        NaN   \n",
       "20                  98.7% ± 0.4%   99.8% ± 0.4%        NaN   \n",
       "21                  99.7% ± 0.3%   99.6% ± 0.4%        NaN   \n",
       "22                  97.6% ± 0.6%   98.0% ± 0.8%        NaN   \n",
       "23                  94.7% ± 0.7%   97.8% ± 0.9%        NaN   \n",
       "24                  98.5% ± 0.3%   98.6% ± 0.9%        NaN   \n",
       "25                  20.9% ± 1.1%            NaN        NaN   \n",
       "26                  12.3% ± 0.4%            NaN        NaN   \n",
       "27                  16.9% ± 1.5%            NaN        NaN   \n",
       "28                   6.6% ± 0.4%            NaN        NaN   \n",
       "29                  14.0% ± 0.1%            NaN        NaN   \n",
       "30                  99.9% ± 0.1%            NaN        NaN   \n",
       "\n",
       "   Attack Success Rate (LLM)     Unnamed: 6 Unnamed: 7 Response Quality  \\\n",
       "1                        NaN   37.8% ± 3.1%        NaN              NaN   \n",
       "2                7.0% ± 0.4%   21.6% ± 2.7%        NaN      5.1% ± 0.6%   \n",
       "3               12.0% ± 1.3%   26.0% ± 2.0%        NaN     65.6% ± 1.7%   \n",
       "4                        NaN   37.4% ± 1.4%        NaN              NaN   \n",
       "5                1.3% ± 0.2%    3.8% ± 0.4%        NaN      2.5% ± 0.2%   \n",
       "6                        NaN  100.0% ± 0.0%        NaN              NaN   \n",
       "7                        NaN   99.6% ± 0.4%        NaN              NaN   \n",
       "8               51.6% ± 1.8%   73.0% ± 2.1%        NaN      7.1% ± 0.8%   \n",
       "9               94.8% ± 0.5%  100.0% ± 0.0%        NaN     11.0% ± 0.4%   \n",
       "10                       NaN   98.4% ± 1.1%        NaN              NaN   \n",
       "11               1.8% ± 0.4%    2.0% ± 1.5%        NaN      2.7% ± 0.3%   \n",
       "12                       NaN  100.0% ± 0.0%        NaN              NaN   \n",
       "13                       NaN   99.0% ± 0.8%        NaN              NaN   \n",
       "14              95.3% ± 1.3%   98.6% ± 1.1%        NaN      4.1% ± 0.6%   \n",
       "15             100.0% ± 0.1%  100.0% ± 0.0%        NaN      2.3% ± 0.8%   \n",
       "16                       NaN   99.8% ± 0.4%        NaN              NaN   \n",
       "17              88.0% ± 0.7%   87.6% ± 1.7%        NaN      2.3% ± 0.6%   \n",
       "18                       NaN   99.0% ± 1.0%        NaN              NaN   \n",
       "19                       NaN   99.2% ± 0.7%        NaN              NaN   \n",
       "20              96.1% ± 0.6%   98.2% ± 0.9%        NaN      0.3% ± 0.3%   \n",
       "21              99.9% ± 0.1%   99.6% ± 0.4%        NaN      0.0% ± 0.1%   \n",
       "22                       NaN  100.0% ± 0.0%        NaN              NaN   \n",
       "23              94.0% ± 0.6%   97.8% ± 0.9%        NaN      0.5% ± 0.3%   \n",
       "24                       NaN   98.8% ± 1.0%        NaN              NaN   \n",
       "25                       NaN            NaN        NaN              NaN   \n",
       "26              12.4% ± 1.8%            NaN        NaN      5.0% ± 0.3%   \n",
       "27              18.0% ± 1.1%            NaN        NaN     66.6% ± 1.2%   \n",
       "28                       NaN            NaN        NaN              NaN   \n",
       "29               1.1% ± 0.1%            NaN        NaN      2.8% ± 0.3%   \n",
       "30                       NaN            NaN        NaN              NaN   \n",
       "\n",
       "      Unnamed: 9         Cost Unnamed: 11 Unnamed: 12 Utility Unnamed: 14  \n",
       "1    2.6% ± 1.1%    8.8 ± 0.0         NaN      2.59GB     NaN         NaN  \n",
       "2    3.2% ± 0.7%    9.9 ± 0.0         NaN      4.96GB     NaN         NaN  \n",
       "3   42.4% ± 3.7%   12.5 ± 0.0         NaN      8.07GB     NaN         NaN  \n",
       "4   47.8% ± 2.8%    9.9 ± 0.0         NaN     17.23GB     NaN         NaN  \n",
       "5    3.8% ± 1.3%    9.8 ± 0.2         NaN     18.32GB     NaN         NaN  \n",
       "6    4.6% ± 0.4%   10.4 ± 0.0         NaN     16.73GB     NaN         NaN  \n",
       "7    0.8% ± 1.0%    8.9 ± 0.0         NaN      2.62GB     NaN         NaN  \n",
       "8    3.4% ± 1.3%   10.1 ± 0.0         NaN      4.95GB     NaN         NaN  \n",
       "9    3.0% ± 0.6%   12.6 ± 0.0         NaN      8.06GB     NaN         NaN  \n",
       "10   7.4% ± 2.3%   10.2 ± 0.0         NaN     17.81GB     NaN         NaN  \n",
       "11   0.6% ± 0.4%    9.9 ± 0.2         NaN     18.97GB     NaN         NaN  \n",
       "12   1.0% ± 0.0%   10.9 ± 0.0         NaN     17.27GB     NaN         NaN  \n",
       "13   1.8% ± 0.7%   16.4 ± 0.0        2:59      4.62GB     NaN         NaN  \n",
       "14   3.6% ± 1.2%   19.5 ± 0.0        4:57      8.33GB     NaN         NaN  \n",
       "15   5.4% ± 1.4%   24.5 ± 0.0        2:14     14.65GB     NaN         NaN  \n",
       "16   6.8% ± 1.0%   18.7 ± 0.0        2:17     32.11GB     NaN         NaN  \n",
       "17   5.4% ± 0.9%   21.1 ± 0.0        4:05     33.48GB     NaN         NaN  \n",
       "18   4.2% ± 0.9%   21.4 ± 0.0        4:07     30.39GB     NaN         NaN  \n",
       "19   0.4% ± 0.7%   16.6 ± 0.0        2:59      5.96GB     NaN         NaN  \n",
       "20   1.0% ± 0.6%   19.2 ± 0.0        4:57     10.60GB     NaN         NaN  \n",
       "21   0.2% ± 0.4%   24.8 ± 0.0        2:14     16.95GB     NaN         NaN  \n",
       "22   0.8% ± 0.4%   19.1 ± 0.0        2:17     32.05GB     NaN         NaN  \n",
       "23   0.2% ± 0.4%   21.6 ± 0.0        4:05     33.49GB     NaN         NaN  \n",
       "24   1.4% ± 1.2%   21.9 ± 0.0        4:07     30.39GB     NaN         NaN  \n",
       "25           NaN   95.1 ± 0.1         NaN      2.59GB     NaN         NaN  \n",
       "26           NaN  106.9 ± 0.5         NaN      4.96GB     NaN         NaN  \n",
       "27           NaN  136.8 ± 0.0         NaN      8.07GB     NaN         NaN  \n",
       "28           NaN  110.6 ± 0.2         NaN     17.23GB     NaN         NaN  \n",
       "29           NaN  104.9 ± 2.4         NaN     18.32GB     NaN         NaN  \n",
       "30           NaN  120.1 ± 0.1         NaN     16.73GB     NaN         NaN  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "def format_latex_table(latex_string, header_replace ):\n",
    "    # Replace the table header\n",
    "    \n",
    "    # Find where the original table begins and replace with our custom header\n",
    "    start_idx = latex_string.find(r\"\\begin{tabular}\")\n",
    "    end_idx = latex_string.find(r\"\\midrule\") + len(r\"\\midrule\")\n",
    "    modified_latex = header_replace + latex_string[end_idx:]\n",
    "    \n",
    "    # Add multirow for each method group and add midrule separators between methods\n",
    "    methods = [\"Baseline\", \"Prefix Injection\", \"Ablation\", \"Ablation + Prefix Injection\", \"Output Aware\"]\n",
    "    current_method = None\n",
    "    \n",
    "    # Split the table into lines for processing\n",
    "    lines = modified_latex.split('\\n')\n",
    "    processed_lines = []\n",
    "    \n",
    "    # Process the header part\n",
    "    header_end_idx = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        processed_lines.append(line)\n",
    "        if r\"\\midrule\" in line:\n",
    "            header_end_idx = i\n",
    "            break\n",
    "    \n",
    "    # Process the data rows\n",
    "    for i in range(header_end_idx + 1, len(lines)):\n",
    "        line = lines[i]\n",
    "        \n",
    "        # Skip lines that don't contain data rows\n",
    "        if r\"\\bottomrule\" in line or \"&\" not in line:\n",
    "            processed_lines.append(line)\n",
    "            continue\n",
    "        \n",
    "        # Check if this row starts a new method\n",
    "        method_found = False\n",
    "        for method in methods:\n",
    "            # Make sure we're matching the exact method name at the start of a cell\n",
    "            if re.search(rf'^\\s*{re.escape(method)}\\s*&', line) or re.search(rf'&\\s*{re.escape(method)}\\s*&', line):\n",
    "                # If we're switching to a new method and not the first one, add midrule\n",
    "                if current_method is not None and current_method != method:\n",
    "                    processed_lines.append(r\"\\midrule\")\n",
    "                \n",
    "                # Only replace if we haven't processed this method yet or it's a new occurrence\n",
    "                if current_method != method:\n",
    "                    # Count how many rows this method has\n",
    "                    method_count = sum(1 for l in lines[i:] if \n",
    "                                      re.search(rf'^\\s*{re.escape(method)}\\s*&', l) or \n",
    "                                      re.search(rf'&\\s*{re.escape(method)}\\s*&', l))\n",
    "                    \n",
    "                    # Replace with multirow\n",
    "                    line = re.sub(\n",
    "                        rf'(^|\\s+){re.escape(method)}\\s*&', \n",
    "                        f\"\\\\\\\\multirow{{{method_count}}}{{*}}{{{method}}} &\", \n",
    "                        line, \n",
    "                        count=1\n",
    "                    )\n",
    "                    current_method = method\n",
    "                    method_found = True\n",
    "                break\n",
    "        \n",
    "        processed_lines.append(line)\n",
    "    \n",
    "    # Join the lines back together\n",
    "    modified_latex = '\\n'.join(processed_lines)\n",
    "    \n",
    "    # Fix the table ending\n",
    "    modified_latex = modified_latex.replace(r\"\\end{tabular}\", r\"\\end{tabular}%}\")\n",
    "    \n",
    "    # Fix the closing bracket of resizebox which should have a real %\n",
    "    modified_latex = modified_latex.replace(\"\\\\end{tabular}%}\", \"\\\\end{tabular}%\\n}\")\n",
    "    \n",
    "    return modified_latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small\n",
      "\\resizebox{\\textwidth}{!}{\\%\n",
      "\\begin{tabular}{llccccccccccccc}\n",
      "\\toprule\n",
      "\\textbf{Method} & \\textbf{Model} & \\multicolumn{3}{c}{\\textbf{Attack Success Rate (\\%) (Substrings)}} & \\multicolumn{3}{c}{\\textbf{Attack Success Rate (\\%) (LLM)}} & \\multicolumn{2}{c}{\\textbf{Response Quality (\\%)}} &\n",
      "\\multicolumn{3}{c}{\\textbf{Cost}} & \\multicolumn{2}{c}{\\textbf{Utility Success Rate (\\%)}} \\\\\n",
      "& & AdvBench & MaliciousInstruct & Alpaca & AdvBench & MaliciousInstruct & Alpaca & AdvBench & MaliciousInstruct & Inference (s) & Fitting (m:s) & Memory (GB) & HellaSwag & MMLU \\\\\n",
      "\\midrule\n",
      "\\multirow{1}{*}{Baseline} & Qwen2.0-0.5B & 6.7 ± 0.5 & 33.0 ± 3.5 &  &  & 37.8 ± 3.1 &  &  & 2.6 ± 1.1 & 8.8 ± 0.0 &  & 2.59 &  &  \\\\\n",
      " & Qwen2.5-1.5B & 5.0 ± 0.2 & 21.0 ± 2.4 &  & 7.0 ± 0.4 & 21.6 ± 2.7 &  & 5.1 ± 0.6 & 3.2 ± 0.7 & 9.9 ± 0.0 &  & 4.96 &  &  \\\\\n",
      " & Qwen2.5-3B & 6.2 ± 0.8 & 19.2 ± 1.6 &  & 12.0 ± 1.3 & 26.0 ± 2.0 &  & 65.6 ± 1.7 & 42.4 ± 3.7 & 12.5 ± 0.0 &  & 8.07 &  &  \\\\\n",
      " & Qwen2.5-7B & 3.8 ± 0.4 & 24.8 ± 2.2 &  &  & 37.4 ± 1.4 &  &  & 47.8 ± 2.8 & 9.9 ± 0.0 &  & 17.23 &  &  \\\\\n",
      " & Llama-3.1-8B & 24.0 ± 0.6 & 88.4 ± 2.3 &  & 1.3 ± 0.2 & 3.8 ± 0.4 &  & 2.5 ± 0.2 & 3.8 ± 1.3 & 9.8 ± 0.2 &  & 18.32 &  &  \\\\\n",
      " & Mistral-v0.1-7B & 99.3 ± 0.0 & 100.0 ± 0.0 &  &  & 100.0 ± 0.0 &  &  & 4.6 ± 0.4 & 10.4 ± 0.0 &  & 16.73 &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow{1}{*}{Prefix Injection} & Qwen2.0-0.5B & 94.9 ± 0.7 & 97.6 ± 1.2 &  &  & 99.6 ± 0.4 &  &  & 0.8 ± 1.0 & 8.9 ± 0.0 &  & 2.62 &  &  \\\\\n",
      " & Qwen2.5-1.5B & 47.9 ± 2.2 & 68.4 ± 2.9 &  & 51.6 ± 1.8 & 73.0 ± 2.1 &  & 7.1 ± 0.8 & 3.4 ± 1.3 & 10.1 ± 0.0 &  & 4.95 &  &  \\\\\n",
      " & Qwen2.5-3B & 85.7 ± 1.1 & 98.6 ± 0.9 &  & 94.8 ± 0.5 & 100.0 ± 0.0 &  & 11.0 ± 0.4 & 3.0 ± 0.6 & 12.6 ± 0.0 &  & 8.06 &  &  \\\\\n",
      " & Qwen2.5-7B & 89.4 ± 0.2 & 94.2 ± 1.0 &  &  & 98.4 ± 1.1 &  &  & 7.4 ± 2.3 & 10.2 ± 0.0 &  & 17.81 &  &  \\\\\n",
      " & Llama-3.1-8B & 31.2 ± 0.9 & 71.0 ± 0.4 &  & 1.8 ± 0.4 & 2.0 ± 1.5 &  & 2.7 ± 0.3 & 0.6 ± 0.4 & 9.9 ± 0.2 &  & 18.97 &  &  \\\\\n",
      " & Mistral-v0.1-7B & 99.5 ± 0.0 & 100.0 ± 0.0 &  &  & 100.0 ± 0.0 &  &  & 1.0 ± 0.0 & 10.9 ± 0.0 &  & 17.27 &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow{1}{*}{Ablation} & Qwen2.0-0.5B & 97.4 ± 0.6 & 99.0 ± 0.6 &  &  & 99.0 ± 0.8 &  &  & 1.8 ± 0.7 & 16.4 ± 0.0 & 2:59 & 4.62 &  &  \\\\\n",
      " & Qwen2.5-1.5B & 97.5 ± 0.4 & 99.8 ± 0.4 &  & 95.3 ± 1.3 & 98.6 ± 1.1 &  & 4.1 ± 0.6 & 3.6 ± 1.2 & 19.5 ± 0.0 & 4:57 & 8.33 &  &  \\\\\n",
      " & Qwen2.5-3B & 98.6 ± 0.7 & 98.4 ± 1.1 &  & 100.0 ± 0.1 & 100.0 ± 0.0 &  & 2.3 ± 0.8 & 5.4 ± 1.4 & 24.5 ± 0.0 & 2:14 & 14.65 &  &  \\\\\n",
      " & Qwen2.5-7B & 92.5 ± 0.6 & 99.2 ± 0.7 &  &  & 99.8 ± 0.4 &  &  & 6.8 ± 1.0 & 18.7 ± 0.0 & 2:17 & 32.11 &  &  \\\\\n",
      " & Llama-3.1-8B & 91.1 ± 0.9 & 93.8 ± 1.3 &  & 88.0 ± 0.7 & 87.6 ± 1.7 &  & 2.3 ± 0.6 & 5.4 ± 0.9 & 21.1 ± 0.0 & 4:05 & 33.48 &  &  \\\\\n",
      " & Mistral-v0.1-7B & 95.7 ± 0.6 & 98.8 ± 0.9 &  &  & 99.0 ± 1.0 &  &  & 4.2 ± 0.9 & 21.4 ± 0.0 & 4:07 & 30.39 &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow{1}{*}{Ablation + Prefix Injection} & Qwen2.0-0.5B & 99.1 ± 0.3 & 99.6 ± 0.4 &  &  & 99.2 ± 0.7 &  &  & 0.4 ± 0.7 & 16.6 ± 0.0 & 2:59 & 5.96 &  &  \\\\\n",
      " & Qwen2.5-1.5B & 98.7 ± 0.4 & 99.8 ± 0.4 &  & 96.1 ± 0.6 & 98.2 ± 0.9 &  & 0.3 ± 0.3 & 1.0 ± 0.6 & 19.2 ± 0.0 & 4:57 & 10.60 &  &  \\\\\n",
      " & Qwen2.5-3B & 99.7 ± 0.3 & 99.6 ± 0.4 &  & 99.9 ± 0.1 & 99.6 ± 0.4 &  & 0.0 ± 0.1 & 0.2 ± 0.4 & 24.8 ± 0.0 & 2:14 & 16.95 &  &  \\\\\n",
      " & Qwen2.5-7B & 97.6 ± 0.6 & 98.0 ± 0.8 &  &  & 100.0 ± 0.0 &  &  & 0.8 ± 0.4 & 19.1 ± 0.0 & 2:17 & 32.05 &  &  \\\\\n",
      " & Llama-3.1-8B & 94.7 ± 0.7 & 97.8 ± 0.9 &  & 94.0 ± 0.6 & 97.8 ± 0.9 &  & 0.5 ± 0.3 & 0.2 ± 0.4 & 21.6 ± 0.0 & 4:05 & 33.49 &  &  \\\\\n",
      " & Mistral-v0.1-7B & 98.5 ± 0.3 & 98.6 ± 0.9 &  &  & 98.8 ± 1.0 &  &  & 1.4 ± 1.2 & 21.9 ± 0.0 & 4:07 & 30.39 &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow{1}{*}{Output Aware} & Qwen2.0-0.5B & 20.9 ± 1.1 &  &  &  &  &  &  &  & 95.1 ± 0.1 &  & 2.59 &  &  \\\\\n",
      " & Qwen2.5-1.5B & 12.3 ± 0.4 &  &  & 12.4 ± 1.8 &  &  & 5.0 ± 0.3 &  & 106.9 ± 0.5 &  & 4.96 &  &  \\\\\n",
      " & Qwen2.5-3B & 16.9 ± 1.5 &  &  & 18.0 ± 1.1 &  &  & 66.6 ± 1.2 &  & 136.8 ± 0.0 &  & 8.07 &  &  \\\\\n",
      " & Qwen2.5-7B & 6.6 ± 0.4 &  &  &  &  &  &  &  & 110.6 ± 0.2 &  & 17.23 &  &  \\\\\n",
      " & Llama-3.1-8B & 14.0 ± 0.1 &  &  & 1.1 ± 0.1 &  &  & 2.8 ± 0.3 &  & 104.9 ± 2.4 &  & 18.32 &  &  \\\\\n",
      " & Mistral-v0.1-7B & 99.9 ± 0.1 &  &  &  &  &  &  &  & 120.1 ± 0.1 &  & 16.73 &  &  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the DataFrame to a LaTeX table\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "def escape_percent(df):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_escaped = df.copy()\n",
    "    \n",
    "    # For each column that's a string type\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        # Replace % with \\% in all string values\n",
    "        df_escaped[col] = df_escaped[col].astype(str).str.replace('%', '')\n",
    "    \n",
    "    return df_escaped\n",
    "df = escape_percent(df)\n",
    "\n",
    "def rename_models(df):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_renamed = df.copy()\n",
    "    \n",
    "    # Define model name mappings (add more as needed)\n",
    "    model_mapping = {\n",
    "        'Qwen2-0.5B-Instruct': 'Qwen2.0-0.5B',\n",
    "        'Qwen2.5-1.5B-Instruct': 'Qwen2.5-1.5B',\n",
    "        'Qwen2.5-3B-Instruct': 'Qwen2.5-3B',\n",
    "        'Qwen2.5-7B-Instruct': 'Qwen2.5-7B',\n",
    "        'Llama-3.1-8B-Instruct': 'Llama-3.1-8B',\n",
    "        'Mistral-7B-Instruct-v0.1': 'Mistral-v0.1-7B',\n",
    "    }\n",
    "    \n",
    "    # Apply the renaming if the Model column exists\n",
    "    if 'Model' in df_renamed.columns:\n",
    "        df_renamed['Model'] = df_renamed['Model'].replace(model_mapping)\n",
    "    \n",
    "    return df_renamed\n",
    "\n",
    "df = rename_models(df)\n",
    "\n",
    "# First, generate the basic LaTeX table\n",
    "latex_table = df.to_latex(index=False, na_rep=\"\", escape=False)\n",
    "\n",
    "HEADER_REPLACE = r\"\"\"\\small\n",
    "\\resizebox{\\textwidth}{!}{%\n",
    "\\begin{tabular}{llccccccccccccc}\n",
    "\\toprule\n",
    "\\textbf{Method} & \\textbf{Model} & \\multicolumn{3}{c}{\\textbf{Attack Success Rate (%) (Substrings)}} & \\multicolumn{3}{c}{\\textbf{Attack Success Rate (%) (LLM)}} & \\multicolumn{2}{c}{\\textbf{Response Quality (%)}} &\n",
    "\\multicolumn{3}{c}{\\textbf{Cost}} & \\multicolumn{2}{c}{\\textbf{Utility Success Rate (%)}} \\\\\n",
    "& & AdvBench & MaliciousInstruct & Alpaca & AdvBench & MaliciousInstruct & Alpaca & AdvBench & MaliciousInstruct & Inference (s) & Fitting (m:s) & Memory (GGBB) & HellaSwag & MMLU \\\\\n",
    "\\midrule\"\"\".replace(\"%\", \"\\\\%\")\n",
    "\n",
    "\n",
    "\n",
    "# Apply the formatting\n",
    "formatted_latex = format_latex_table(latex_table, header_replace=HEADER_REPLACE).replace(\"GB\", \"\")\n",
    "\n",
    "\n",
    "# Print the formatted LaTeX table\n",
    "print(formatted_latex)\n",
    "\n",
    "# Save to file\n",
    "with open(\"results/all_latex.tex\", \"w\") as f:\n",
    "    f.write(formatted_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_baseline_differences(df, metric_col, baseline_method=\"Baseline\"):\n",
    "    \"\"\"\n",
    "    Calculate the difference between each method and the baseline method for a specific metric.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the data\n",
    "        metric_col: Column name for the metric to analyze\n",
    "        baseline_method: The name of the baseline method to compare against (default: \"Baseline\")\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with differences from baseline for each method and model\n",
    "    \"\"\"\n",
    "    # Check if the metric column exists\n",
    "    if metric_col not in df.columns:\n",
    "        print(f\"Column {metric_col} not found in dataframe. Available columns: {df.columns}\")\n",
    "        return None\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convert the metric column to numeric if it's not already\n",
    "    df_copy[metric_col] = pd.to_numeric(df_copy[metric_col], errors='coerce')\n",
    "    \n",
    "    # Create a pivot table with methods as rows and models as columns\n",
    "    pivot_df = df_copy.pivot(index=\"Method\", columns=\"Model\", values=metric_col)\n",
    "    \n",
    "    # Check if baseline method exists\n",
    "    if baseline_method not in pivot_df.index:\n",
    "        print(f\"Baseline method '{baseline_method}' not found in the data.\")\n",
    "        return None\n",
    "    \n",
    "    # Extract baseline values for each model\n",
    "    baseline_values = pivot_df.loc[baseline_method]\n",
    "    \n",
    "    # Calculate differences from baseline for each method\n",
    "    diff_df = pivot_df.copy()\n",
    "    for method in diff_df.index:\n",
    "        if method != baseline_method:\n",
    "            diff_df.loc[method] = diff_df.loc[method] - baseline_values\n",
    "    \n",
    "    # For the baseline method itself, set differences to 0\n",
    "    diff_df.loc[baseline_method] = 0\n",
    "    \n",
    "    return diff_df\n",
    "\n",
    "def create_baseline_difference_heatmap(df, metric_col, baseline_method=\"Baseline\", title=None, \n",
    "                                      cmap=\"RdBu_r\", figsize=(14, 10), \n",
    "                                      vmin=None, vmax=None, center=0,\n",
    "                                      annot=True, fmt=\".1f\", annot_kws=None,\n",
    "                                      xlabel=None, ylabel=None, \n",
    "                                      xlabel_fontsize=12, ylabel_fontsize=12):\n",
    "    \"\"\"\n",
    "    Create a heatmap showing differences from baseline for each method.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the data\n",
    "        metric_col: Column name for the metric to analyze\n",
    "        baseline_method: The name of the baseline method to compare against\n",
    "        title: Optional title for the heatmap\n",
    "        cmap: Colormap to use (default: RdBu_r which is good for diverging data)\n",
    "        figsize: Figure size as (width, height)\n",
    "        vmin, vmax: Min and max values for color scaling\n",
    "        center: Center value for diverging colormaps\n",
    "        annot: Whether to annotate cells\n",
    "        fmt: Format string for annotations\n",
    "        annot_kws: Additional kwargs for annotations\n",
    "        xlabel, ylabel: Custom axis labels\n",
    "    \"\"\"\n",
    "    # Calculate differences from baseline\n",
    "    diff_df = calculate_baseline_differences(df, metric_col=metric_col, baseline_method=baseline_method)\n",
    "    \n",
    "    if diff_df is None:\n",
    "        return None\n",
    "    \n",
    "    # Create the figure and axes\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Set default annotation parameters if not provided\n",
    "    if annot_kws is None:\n",
    "        annot_kws = {\"size\": 15}\n",
    "    \n",
    "    # Create the heatmap with a diverging colormap centered at 0\n",
    "    sns.heatmap(diff_df, annot=annot, fmt=fmt, cmap=cmap, \n",
    "                vmin=vmin, vmax=vmax, center=center,\n",
    "                annot_kws=annot_kws, ax=ax)\n",
    "    \n",
    "    # Set title if provided\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=16, pad=20, fontweight='bold')\n",
    "    else:\n",
    "        ax.set_title(f\"Difference from {baseline_method} ({metric_col})\", \n",
    "                    fontsize=16, pad=20, fontweight='bold')\n",
    "    \n",
    "    # Set custom axis labels if provided\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontsize=xlabel_fontsize, labelpad=10, fontweight='bold')\n",
    "    \n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel, fontsize=ylabel_fontsize, labelpad=10, fontweight='bold')\n",
    "    \n",
    "    # Increase font size for tick labels and make them bold\n",
    "    plt.xticks(rotation=30, ha=\"right\", fontsize=16, fontweight='bold')\n",
    "    plt.yticks(fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# Example usage:\n",
    "# create_baseline_difference_heatmap(df, metric_col=\"Attack Succes Rate (Baseline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Model</th>\n",
       "      <th>Attack Succes Rate (Baseline)</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Attack Success Rate (LLM)</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Response Quality</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Utility</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Qwen2.0-0.5B</td>\n",
       "      <td>6.7 ± 0.5</td>\n",
       "      <td>33.0 ± 3.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>37.8 ± 3.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.6 ± 1.1</td>\n",
       "      <td>8.8 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>2.59GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-1.5B</td>\n",
       "      <td>5.0 ± 0.2</td>\n",
       "      <td>21.0 ± 2.4</td>\n",
       "      <td></td>\n",
       "      <td>7.0 ± 0.4</td>\n",
       "      <td>21.6 ± 2.7</td>\n",
       "      <td></td>\n",
       "      <td>5.1 ± 0.6</td>\n",
       "      <td>3.2 ± 0.7</td>\n",
       "      <td>9.9 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>4.96GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-3B</td>\n",
       "      <td>6.2 ± 0.8</td>\n",
       "      <td>19.2 ± 1.6</td>\n",
       "      <td></td>\n",
       "      <td>12.0 ± 1.3</td>\n",
       "      <td>26.0 ± 2.0</td>\n",
       "      <td></td>\n",
       "      <td>65.6 ± 1.7</td>\n",
       "      <td>42.4 ± 3.7</td>\n",
       "      <td>12.5 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>8.07GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>3.8 ± 0.4</td>\n",
       "      <td>24.8 ± 2.2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>37.4 ± 1.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>47.8 ± 2.8</td>\n",
       "      <td>9.9 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>17.23GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>24.0 ± 0.6</td>\n",
       "      <td>88.4 ± 2.3</td>\n",
       "      <td></td>\n",
       "      <td>1.3 ± 0.2</td>\n",
       "      <td>3.8 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td>2.5 ± 0.2</td>\n",
       "      <td>3.8 ± 1.3</td>\n",
       "      <td>9.8 ± 0.2</td>\n",
       "      <td></td>\n",
       "      <td>18.32GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Mistral-v0.1-7B</td>\n",
       "      <td>99.3 ± 0.0</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.6 ± 0.4</td>\n",
       "      <td>10.4 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>16.73GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prefix Injection</td>\n",
       "      <td>Qwen2.0-0.5B</td>\n",
       "      <td>94.9 ± 0.7</td>\n",
       "      <td>97.6 ± 1.2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.6 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.8 ± 1.0</td>\n",
       "      <td>8.9 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>2.62GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-1.5B</td>\n",
       "      <td>47.9 ± 2.2</td>\n",
       "      <td>68.4 ± 2.9</td>\n",
       "      <td></td>\n",
       "      <td>51.6 ± 1.8</td>\n",
       "      <td>73.0 ± 2.1</td>\n",
       "      <td></td>\n",
       "      <td>7.1 ± 0.8</td>\n",
       "      <td>3.4 ± 1.3</td>\n",
       "      <td>10.1 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>4.95GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-3B</td>\n",
       "      <td>85.7 ± 1.1</td>\n",
       "      <td>98.6 ± 0.9</td>\n",
       "      <td></td>\n",
       "      <td>94.8 ± 0.5</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>11.0 ± 0.4</td>\n",
       "      <td>3.0 ± 0.6</td>\n",
       "      <td>12.6 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>8.06GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>89.4 ± 0.2</td>\n",
       "      <td>94.2 ± 1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>98.4 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7.4 ± 2.3</td>\n",
       "      <td>10.2 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>17.81GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>31.2 ± 0.9</td>\n",
       "      <td>71.0 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td>1.8 ± 0.4</td>\n",
       "      <td>2.0 ± 1.5</td>\n",
       "      <td></td>\n",
       "      <td>2.7 ± 0.3</td>\n",
       "      <td>0.6 ± 0.4</td>\n",
       "      <td>9.9 ± 0.2</td>\n",
       "      <td></td>\n",
       "      <td>18.97GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>Mistral-v0.1-7B</td>\n",
       "      <td>99.5 ± 0.0</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "      <td>10.9 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>17.27GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ablation</td>\n",
       "      <td>Qwen2.0-0.5B</td>\n",
       "      <td>97.4 ± 0.6</td>\n",
       "      <td>99.0 ± 0.6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.0 ± 0.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.8 ± 0.7</td>\n",
       "      <td>16.4 ± 0.0</td>\n",
       "      <td>2:59</td>\n",
       "      <td>4.62GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-1.5B</td>\n",
       "      <td>97.5 ± 0.4</td>\n",
       "      <td>99.8 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td>95.3 ± 1.3</td>\n",
       "      <td>98.6 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td>4.1 ± 0.6</td>\n",
       "      <td>3.6 ± 1.2</td>\n",
       "      <td>19.5 ± 0.0</td>\n",
       "      <td>4:57</td>\n",
       "      <td>8.33GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-3B</td>\n",
       "      <td>98.6 ± 0.7</td>\n",
       "      <td>98.4 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td>100.0 ± 0.1</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>2.3 ± 0.8</td>\n",
       "      <td>5.4 ± 1.4</td>\n",
       "      <td>24.5 ± 0.0</td>\n",
       "      <td>2:14</td>\n",
       "      <td>14.65GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>92.5 ± 0.6</td>\n",
       "      <td>99.2 ± 0.7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.8 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6.8 ± 1.0</td>\n",
       "      <td>18.7 ± 0.0</td>\n",
       "      <td>2:17</td>\n",
       "      <td>32.11GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>91.1 ± 0.9</td>\n",
       "      <td>93.8 ± 1.3</td>\n",
       "      <td></td>\n",
       "      <td>88.0 ± 0.7</td>\n",
       "      <td>87.6 ± 1.7</td>\n",
       "      <td></td>\n",
       "      <td>2.3 ± 0.6</td>\n",
       "      <td>5.4 ± 0.9</td>\n",
       "      <td>21.1 ± 0.0</td>\n",
       "      <td>4:05</td>\n",
       "      <td>33.48GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>Mistral-v0.1-7B</td>\n",
       "      <td>95.7 ± 0.6</td>\n",
       "      <td>98.8 ± 0.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.0 ± 1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.2 ± 0.9</td>\n",
       "      <td>21.4 ± 0.0</td>\n",
       "      <td>4:07</td>\n",
       "      <td>30.39GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ablation + Prefix Injection</td>\n",
       "      <td>Qwen2.0-0.5B</td>\n",
       "      <td>99.1 ± 0.3</td>\n",
       "      <td>99.6 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99.2 ± 0.7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.4 ± 0.7</td>\n",
       "      <td>16.6 ± 0.0</td>\n",
       "      <td>2:59</td>\n",
       "      <td>5.96GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-1.5B</td>\n",
       "      <td>98.7 ± 0.4</td>\n",
       "      <td>99.8 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td>96.1 ± 0.6</td>\n",
       "      <td>98.2 ± 0.9</td>\n",
       "      <td></td>\n",
       "      <td>0.3 ± 0.3</td>\n",
       "      <td>1.0 ± 0.6</td>\n",
       "      <td>19.2 ± 0.0</td>\n",
       "      <td>4:57</td>\n",
       "      <td>10.60GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-3B</td>\n",
       "      <td>99.7 ± 0.3</td>\n",
       "      <td>99.6 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td>99.9 ± 0.1</td>\n",
       "      <td>99.6 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td>0.0 ± 0.1</td>\n",
       "      <td>0.2 ± 0.4</td>\n",
       "      <td>24.8 ± 0.0</td>\n",
       "      <td>2:14</td>\n",
       "      <td>16.95GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>97.6 ± 0.6</td>\n",
       "      <td>98.0 ± 0.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.8 ± 0.4</td>\n",
       "      <td>19.1 ± 0.0</td>\n",
       "      <td>2:17</td>\n",
       "      <td>32.05GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>94.7 ± 0.7</td>\n",
       "      <td>97.8 ± 0.9</td>\n",
       "      <td></td>\n",
       "      <td>94.0 ± 0.6</td>\n",
       "      <td>97.8 ± 0.9</td>\n",
       "      <td></td>\n",
       "      <td>0.5 ± 0.3</td>\n",
       "      <td>0.2 ± 0.4</td>\n",
       "      <td>21.6 ± 0.0</td>\n",
       "      <td>4:05</td>\n",
       "      <td>33.49GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>Mistral-v0.1-7B</td>\n",
       "      <td>98.5 ± 0.3</td>\n",
       "      <td>98.6 ± 0.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>98.8 ± 1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.4 ± 1.2</td>\n",
       "      <td>21.9 ± 0.0</td>\n",
       "      <td>4:07</td>\n",
       "      <td>30.39GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Output Aware</td>\n",
       "      <td>Qwen2.0-0.5B</td>\n",
       "      <td>20.9 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>95.1 ± 0.1</td>\n",
       "      <td></td>\n",
       "      <td>2.59GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-1.5B</td>\n",
       "      <td>12.3 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12.4 ± 1.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5.0 ± 0.3</td>\n",
       "      <td></td>\n",
       "      <td>106.9 ± 0.5</td>\n",
       "      <td></td>\n",
       "      <td>4.96GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-3B</td>\n",
       "      <td>16.9 ± 1.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>18.0 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>66.6 ± 1.2</td>\n",
       "      <td></td>\n",
       "      <td>136.8 ± 0.0</td>\n",
       "      <td></td>\n",
       "      <td>8.07GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>6.6 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>110.6 ± 0.2</td>\n",
       "      <td></td>\n",
       "      <td>17.23GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>14.0 ± 0.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.1 ± 0.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.8 ± 0.3</td>\n",
       "      <td></td>\n",
       "      <td>104.9 ± 2.4</td>\n",
       "      <td></td>\n",
       "      <td>18.32GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>Mistral-v0.1-7B</td>\n",
       "      <td>99.9 ± 0.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>120.1 ± 0.1</td>\n",
       "      <td></td>\n",
       "      <td>16.73GB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Method            Model  \\\n",
       "1                      Baseline     Qwen2.0-0.5B   \n",
       "2                                   Qwen2.5-1.5B   \n",
       "3                                     Qwen2.5-3B   \n",
       "4                                     Qwen2.5-7B   \n",
       "5                                   Llama-3.1-8B   \n",
       "6                                Mistral-v0.1-7B   \n",
       "7              Prefix Injection     Qwen2.0-0.5B   \n",
       "8                                   Qwen2.5-1.5B   \n",
       "9                                     Qwen2.5-3B   \n",
       "10                                    Qwen2.5-7B   \n",
       "11                                  Llama-3.1-8B   \n",
       "12                               Mistral-v0.1-7B   \n",
       "13                     Ablation     Qwen2.0-0.5B   \n",
       "14                                  Qwen2.5-1.5B   \n",
       "15                                    Qwen2.5-3B   \n",
       "16                                    Qwen2.5-7B   \n",
       "17                                  Llama-3.1-8B   \n",
       "18                               Mistral-v0.1-7B   \n",
       "19  Ablation + Prefix Injection     Qwen2.0-0.5B   \n",
       "20                                  Qwen2.5-1.5B   \n",
       "21                                    Qwen2.5-3B   \n",
       "22                                    Qwen2.5-7B   \n",
       "23                                  Llama-3.1-8B   \n",
       "24                               Mistral-v0.1-7B   \n",
       "25                 Output Aware     Qwen2.0-0.5B   \n",
       "26                                  Qwen2.5-1.5B   \n",
       "27                                    Qwen2.5-3B   \n",
       "28                                    Qwen2.5-7B   \n",
       "29                                  Llama-3.1-8B   \n",
       "30                               Mistral-v0.1-7B   \n",
       "\n",
       "   Attack Succes Rate (Baseline)   Unnamed: 3 Unnamed: 4  \\\n",
       "1                      6.7 ± 0.5   33.0 ± 3.5              \n",
       "2                      5.0 ± 0.2   21.0 ± 2.4              \n",
       "3                      6.2 ± 0.8   19.2 ± 1.6              \n",
       "4                      3.8 ± 0.4   24.8 ± 2.2              \n",
       "5                     24.0 ± 0.6   88.4 ± 2.3              \n",
       "6                     99.3 ± 0.0  100.0 ± 0.0              \n",
       "7                     94.9 ± 0.7   97.6 ± 1.2              \n",
       "8                     47.9 ± 2.2   68.4 ± 2.9              \n",
       "9                     85.7 ± 1.1   98.6 ± 0.9              \n",
       "10                    89.4 ± 0.2   94.2 ± 1.0              \n",
       "11                    31.2 ± 0.9   71.0 ± 0.4              \n",
       "12                    99.5 ± 0.0  100.0 ± 0.0              \n",
       "13                    97.4 ± 0.6   99.0 ± 0.6              \n",
       "14                    97.5 ± 0.4   99.8 ± 0.4              \n",
       "15                    98.6 ± 0.7   98.4 ± 1.1              \n",
       "16                    92.5 ± 0.6   99.2 ± 0.7              \n",
       "17                    91.1 ± 0.9   93.8 ± 1.3              \n",
       "18                    95.7 ± 0.6   98.8 ± 0.9              \n",
       "19                    99.1 ± 0.3   99.6 ± 0.4              \n",
       "20                    98.7 ± 0.4   99.8 ± 0.4              \n",
       "21                    99.7 ± 0.3   99.6 ± 0.4              \n",
       "22                    97.6 ± 0.6   98.0 ± 0.8              \n",
       "23                    94.7 ± 0.7   97.8 ± 0.9              \n",
       "24                    98.5 ± 0.3   98.6 ± 0.9              \n",
       "25                    20.9 ± 1.1                           \n",
       "26                    12.3 ± 0.4                           \n",
       "27                    16.9 ± 1.5                           \n",
       "28                     6.6 ± 0.4                           \n",
       "29                    14.0 ± 0.1                           \n",
       "30                    99.9 ± 0.1                           \n",
       "\n",
       "   Attack Success Rate (LLM)   Unnamed: 6 Unnamed: 7 Response Quality  \\\n",
       "1                              37.8 ± 3.1                               \n",
       "2                  7.0 ± 0.4   21.6 ± 2.7                   5.1 ± 0.6   \n",
       "3                 12.0 ± 1.3   26.0 ± 2.0                  65.6 ± 1.7   \n",
       "4                              37.4 ± 1.4                               \n",
       "5                  1.3 ± 0.2    3.8 ± 0.4                   2.5 ± 0.2   \n",
       "6                             100.0 ± 0.0                               \n",
       "7                              99.6 ± 0.4                               \n",
       "8                 51.6 ± 1.8   73.0 ± 2.1                   7.1 ± 0.8   \n",
       "9                 94.8 ± 0.5  100.0 ± 0.0                  11.0 ± 0.4   \n",
       "10                             98.4 ± 1.1                               \n",
       "11                 1.8 ± 0.4    2.0 ± 1.5                   2.7 ± 0.3   \n",
       "12                            100.0 ± 0.0                               \n",
       "13                             99.0 ± 0.8                               \n",
       "14                95.3 ± 1.3   98.6 ± 1.1                   4.1 ± 0.6   \n",
       "15               100.0 ± 0.1  100.0 ± 0.0                   2.3 ± 0.8   \n",
       "16                             99.8 ± 0.4                               \n",
       "17                88.0 ± 0.7   87.6 ± 1.7                   2.3 ± 0.6   \n",
       "18                             99.0 ± 1.0                               \n",
       "19                             99.2 ± 0.7                               \n",
       "20                96.1 ± 0.6   98.2 ± 0.9                   0.3 ± 0.3   \n",
       "21                99.9 ± 0.1   99.6 ± 0.4                   0.0 ± 0.1   \n",
       "22                            100.0 ± 0.0                               \n",
       "23                94.0 ± 0.6   97.8 ± 0.9                   0.5 ± 0.3   \n",
       "24                             98.8 ± 1.0                               \n",
       "25                                                                      \n",
       "26                12.4 ± 1.8                                5.0 ± 0.3   \n",
       "27                18.0 ± 1.1                               66.6 ± 1.2   \n",
       "28                                                                      \n",
       "29                 1.1 ± 0.1                                2.8 ± 0.3   \n",
       "30                                                                      \n",
       "\n",
       "    Unnamed: 9         Cost Unnamed: 11 Unnamed: 12 Utility Unnamed: 14  \n",
       "1    2.6 ± 1.1    8.8 ± 0.0                  2.59GB                      \n",
       "2    3.2 ± 0.7    9.9 ± 0.0                  4.96GB                      \n",
       "3   42.4 ± 3.7   12.5 ± 0.0                  8.07GB                      \n",
       "4   47.8 ± 2.8    9.9 ± 0.0                 17.23GB                      \n",
       "5    3.8 ± 1.3    9.8 ± 0.2                 18.32GB                      \n",
       "6    4.6 ± 0.4   10.4 ± 0.0                 16.73GB                      \n",
       "7    0.8 ± 1.0    8.9 ± 0.0                  2.62GB                      \n",
       "8    3.4 ± 1.3   10.1 ± 0.0                  4.95GB                      \n",
       "9    3.0 ± 0.6   12.6 ± 0.0                  8.06GB                      \n",
       "10   7.4 ± 2.3   10.2 ± 0.0                 17.81GB                      \n",
       "11   0.6 ± 0.4    9.9 ± 0.2                 18.97GB                      \n",
       "12   1.0 ± 0.0   10.9 ± 0.0                 17.27GB                      \n",
       "13   1.8 ± 0.7   16.4 ± 0.0        2:59      4.62GB                      \n",
       "14   3.6 ± 1.2   19.5 ± 0.0        4:57      8.33GB                      \n",
       "15   5.4 ± 1.4   24.5 ± 0.0        2:14     14.65GB                      \n",
       "16   6.8 ± 1.0   18.7 ± 0.0        2:17     32.11GB                      \n",
       "17   5.4 ± 0.9   21.1 ± 0.0        4:05     33.48GB                      \n",
       "18   4.2 ± 0.9   21.4 ± 0.0        4:07     30.39GB                      \n",
       "19   0.4 ± 0.7   16.6 ± 0.0        2:59      5.96GB                      \n",
       "20   1.0 ± 0.6   19.2 ± 0.0        4:57     10.60GB                      \n",
       "21   0.2 ± 0.4   24.8 ± 0.0        2:14     16.95GB                      \n",
       "22   0.8 ± 0.4   19.1 ± 0.0        2:17     32.05GB                      \n",
       "23   0.2 ± 0.4   21.6 ± 0.0        4:05     33.49GB                      \n",
       "24   1.4 ± 1.2   21.9 ± 0.0        4:07     30.39GB                      \n",
       "25               95.1 ± 0.1                  2.59GB                      \n",
       "26              106.9 ± 0.5                  4.96GB                      \n",
       "27              136.8 ± 0.0                  8.07GB                      \n",
       "28              110.6 ± 0.2                 17.23GB                      \n",
       "29              104.9 ± 2.4                 18.32GB                      \n",
       "30              120.1 ± 0.1                 16.73GB                      "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
